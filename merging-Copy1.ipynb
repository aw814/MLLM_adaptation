{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fa65578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster version: all dependencies should be installed in your virtualenv / conda env.\n",
    "# No in-notebook pip installs needed here.\n",
    "import os, re  # keep imports if you need them later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e16da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Imports & basic config\n",
    "# ============================================================\n",
    "import os, json, glob, math, random, shutil, time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from safetensors.torch import load_file as safe_load_file\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "from peft.utils import set_peft_model_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbaf0211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/wangzn/projects/aip-vshwartz/wangzn/adapter_mllm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Absolute project root on the cluster\n",
    "PROJECT_ROOT = Path(\"/home/wangzn/projects/aip-vshwartz/wangzn/adapter_mllm\")\n",
    "print(\"Project root:\", PROJECT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ca859b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd944811e9a140709b73dc83a1560841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------\n",
    "# Repro & device\n",
    "# --------------------\n",
    "SEED = 3407\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ============================================================\n",
    "# Base LM + tokenizer (also used as embedder + base baseline)\n",
    "# ============================================================\n",
    "BASE_MODEL_NAME = \"unsloth/Meta-Llama-3.1-8B\"\n",
    "MAX_SEQ_LEN     = 2048\n",
    "DTYPE           = None   # we'll resolve this below\n",
    "\n",
    "# choose a sane default dtype if not set\n",
    "if DTYPE is None:\n",
    "    if DEVICE == \"cuda\":\n",
    "        # bf16 if supported, else fp16\n",
    "        DTYPE = torch.bfloat16 if torch.cuda.is_bf16_supported() else torch.float16\n",
    "    else:\n",
    "        DTYPE = torch.float32\n",
    "\n",
    "# Tokenizer\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "if base_tokenizer.pad_token is None:\n",
    "    base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "base_tokenizer.padding_side = \"left\"\n",
    "SPECIAL_IDS = set(getattr(base_tokenizer, \"all_special_ids\", []) or [])\n",
    "\n",
    "# Base model (used for embeddings + baseline generation)\n",
    "emb_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    dtype=DTYPE,\n",
    ")\n",
    "emb_model = emb_model.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79e74972-de01-4308-adee-05ac9055c0e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a534be148bae49709a3bd7e56dfcce4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a54d279-3b36-4265-9636-cc9d823804ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052834921ca6440fa66f3ba2b0e57db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data] Loaded 100 eval texts for file=ai4bharat_IndicParaphrase\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "DATASET_NAME = \"Hindi-data-hub/odaigen_hindi_pre_trained_sp\"\n",
    "TARGET_FILE = \"ai4bharat_IndicParaphrase\"\n",
    "MAX_EVAL = 100\n",
    "\n",
    "def load_eval_texts_by_filename(max_eval: int, target_file: str):\n",
    "    ds = load_dataset(DATASET_NAME, split=\"train\", streaming=True)\n",
    "\n",
    "    selected_texts = []\n",
    "    for row in ds:\n",
    "        if row.get(\"file_name\") == target_file:\n",
    "            content = row.get(\"content\", \"\")\n",
    "            if isinstance(content, str) and content.strip():\n",
    "                selected_texts.append(content)\n",
    "            if len(selected_texts) >= max_eval:\n",
    "                break\n",
    "\n",
    "    return selected_texts\n",
    "\n",
    "eval_texts = load_eval_texts_by_filename(MAX_EVAL, TARGET_FILE)\n",
    "print(f\"[Data] Loaded {len(eval_texts)} eval texts for file={TARGET_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4505a934-f949-48d4-8c97-23d0e490aaad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['प्रदेश के युवाओं को निजी उद्योगों में 75 प्रतिशत आरक्षण देंगे।',\n",
       " 'डेरा प्रमुख गुरमीत राम रहीम को पंचकूला कोर्ट ने यौन शोषण मामले में दोषी करार दिया है.',\n",
       " 'ऐसे में इसे रकम की जरूरत होगी।',\n",
       " 'घायलों को अस्पताल में देर से मिला इलाज',\n",
       " 'पुलिस ने उनकी कॉल डीटेल्स मंगवाईं।',\n",
       " 'शहर भर में हर कहीं कचरे का अंबार नजऱ आता है।',\n",
       " 'इन छात्रों में से कई छात्रों को चोट भी आई है।',\n",
       " 'यह कोई आसान व सहज बात नहीं थी।',\n",
       " 'उन्होंने पार्टी आयोजित की, जिसमें करीना कपूर, करिश्मा कपूर, मलाइका अरोड़ा और अर्जुन कपूर सहित कई हस्तियां नज़र आईं।',\n",
       " '‘राम जन्मभूमि पर अगर राम का मंदिर नहीं बनेगा तो किसका बनेगा?',\n",
       " 'पुलिस मामले की जांच में जुट गई है और शव की शिनाख्तगी के प्रयास कर रही है।',\n",
       " 'दिल्ली पुलिस फायरिंग की बात को खारिज कर रही है।',\n",
       " 'लोगों का कहना हैः',\n",
       " 'मशहूर कॉमेडियन और फिल्म अभिनेता कपिल शर्मा जल्द ही टीवी पर वापसी करने वाले है, कुछ समय पहले हुए कुछ विवादों के बाद से कपिल शर्मा टीवी शो से दुरी बनाये हुए थे लेकिन कुछ समय पहले उन्होंने खुद अपने फैन्स को खबर दी है की वे जल्द ही टीवी पर वापसी करने वाले है और साथ ही उनसे जुड़े सूत्रों की मानें तो कपिल जल्द ही शादी के बंधन में बंधने वाले हैं। कपिल ने एक इंटरव्यू के दौरान बताया था कि मुझे गिन्नी से अच्छी लड़की नहीं मिल सकती। गिन्नी ने मुझे बुरे वक्त में चलना सिखाया हैं।',\n",
       " 'बीमारी के चलते उसे जिला चिकित्सालय में उपचार हेतु लाया गया था.',\n",
       " 'लेकिन धवन की एक और साइड है।',\n",
       " 'तुम इसके लिए बिल्कुल सही हो।',\n",
       " 'नेहा की शादी की तस्वीरें सोशल मीडिया परा छाई हुई हैं।',\n",
       " 'हादसे में एक छात्रा सहित 17 लोग घायल हो गए।',\n",
       " 'कैबिनेट की सहमति थी।',\n",
       " 'साल 2021 का मूवी कैलेंडर लगातार भर रहा है।',\n",
       " 'कुलपति की बर्खास्तगी की मांग को लेकर सड़क पर उतरे JNU के छात्र',\n",
       " 'कश्मीर भारत का एक अभिन्न और आंतरिक हिस्सा है जो देश से कभी अलग नहीं होगा।',\n",
       " 'संजना सांघी की मुख्य अभिनेत्री के तौर पर डेब्यू फिल्म बॉलीवुड के दिवंगत अभिनेता सुशांत सिंह राजपूत के साथ थी।',\n",
       " 'हालांकि यह फिल्म टिकट खिड़की पर खास कामयाब नही हो सकी.',\n",
       " 'उसे तब तक रगड़ें जब तक छिलका भूरे रंग का न हो जाए।',\n",
       " 'उनके घर से पुलिस को एके-47 और हैंड ग्रेनेड जैसे हथियार मिले थे',\n",
       " 'कांग्रेस के कई दिग्गजों के नाम इस लिस्ट में हैं.',\n",
       " 'उत्तराखंड में भी भाजपा सारी सीटें जीतती दिख रही है।',\n",
       " 'भर्ती प्रक्रिया के लिए उपस्थित होने वाले उम्मीदवार यूपीएससी की आधिकारिक साइट upsc. gov. in के माध्यम से अपना परिणाम देख सकते हैं।',\n",
       " 'Eleven Dead Bodies Hanging From Ceiling Found In A House In Delhi Burari Area Mk | दिल्ली के बुराड़ी में घर से मिले 11 शव, मुंह और आंखों पर बंधी थी काली पट्टी - Firstpost Hindi',\n",
       " 'कांग्रेस अध्यक्ष राहुल गांधी ने ट्वीट कर गुजरात की हार स्वीकार कर ली है। राहुल ने कहा कि कांग्रेस पार्टी जनता के फैसले का स्वागत करती है। और दोनों राज्यों की नई सरकार को बधाई देती है। हार की जिम्मेदारी अपने ऊपर लेते हुए राहुल ने कहा कि हिमाचल और गुजरात के लोगों ने कांग्रेस को जिस तरह से समर्थन दिया, उसके लिए शु\\u200cक्रिया।',\n",
       " 'इस घटना में पति व पत्नि को अनेकों चोटें आई थीं।',\n",
       " 'घरवाले उसे अस्पताल लेकर गए और इलाज करवाया।',\n",
       " 'जानकारी मिलने पर वरिष्ठ पुलिस निरीक्षक आर. तिवारी, सहायक निरीक्षक नरेंद्र निसवाडे और हवलदार संजय बतकल घटनास्थल पर पहुंचे।',\n",
       " 'इस स्मार्टफोन में सेल्फी के लिए 25 मेगापिक्सेल का कैमरा लगा है।',\n",
       " 'सीबीआई ने तीनों आरोपियों के खिलाफ आरोप-पत्र पेश किया।',\n",
       " 'आरआरबी एनटीपीसी एग्जाम के संबंध में अधिक जानकारी हासिल करने के लिए उम्मीदवार रेलवे भर्ती बोर्ड की आधिकारिक वेबसाइट पर नजर बनाए रखें.',\n",
       " 'इस अवसर पर सातरोल खाप के महासचिव रणवीर सिंह लोहान भी साथ थे।',\n",
       " 'इससे पहले आंध्रप्रदेश भाजपा अध्यक्ष हरि बाबू ने अपने पद से इस्तीफा दिया था.',\n",
       " 'मित्र, भाई-बहन के साथ संबंधों में घनिष्ठता आएगी।',\n",
       " 'बैठक में विश्वविद्यालय के तमाम अधिकारी मौजूद थे।',\n",
       " 'लेकिन पुलिस जांच में अभी भी गुत्थी उलझी हुई है।',\n",
       " 'प्रियंका चोपड़ा की फिल्म द स्काई इज़ पिंक में फरहान अख्तर और जायरा वसीम की भी अहम भूमिकाएं हैं।',\n",
       " '10वीं सीट भी बीजेपी ने जीत ली है।',\n",
       " 'रेलवे रिक्रूटमेंट बोर्ड ने नार्दन रेलवे के कई पदों पर वैकेंसी निकाली है।',\n",
       " 'समारोह के मुख्य वक्ता प्रो.',\n",
       " 'अंतर्राष्ट्रीय बाजार में कच्चे तेल के दाम में तेजी की वापसी के साथ पेट्रोल और डीजल के दाम में राहत . पढ़ें',\n",
       " 'ICC World Test Championship के फाइनल में ऐसे पहुंचेगी टीम इंडिया, ये है आगे का रास्ता',\n",
       " 'पेट्रोल और डीजल दोनों हुए सस्ते, जानिए कितना कम देना होगा अब दाम',\n",
       " 'लिस्टिंग के मुताबिक, फोन में 5,000 एमएएच की दमदार बैटरी दी जा सकती है।',\n",
       " 'दोनों धोती-कुर्ता पहने हुए थे।',\n",
       " 'जिसके बाद वन विभाग, प्रशासन औप पुलिस की टीम मौके पर पहुंच गई।',\n",
       " 'प्रदर्शनी स्पर्धा विजेताओं को पदक प्रदान किए गए।',\n",
       " 'बहरहाल, यह जांच का विषय है।',\n",
       " 'वाहनों का दबाव शहर में दिन ब दिन बढ़ता जा रहा है।',\n",
       " 'वह फैंस के साथ अपनी कई हॉट फोटोज और वीडियोज शेयर करती हैं.',\n",
       " 'जो कहना होता है सामने कहता हूं।',\n",
       " 'इसके चलते निवेशकों का विश्वास एक बार फिर से लौटा है।',\n",
       " 'कोसमपाट घरघोडा मण्डल में भारत के छत्तीसगढ़ राज्य के अन्तर्गत रायगढ़ जिले का एक गाँव है।',\n",
       " 'वहीं 5,272 लोगों ने संक्रमण को मात दिया और अस्पताल से डिस्चार्ज किए गए।',\n",
       " 'Petrol-Diesel Price in India :\\xa0पेट्रोलियम कीमतों की बात करें तो नेपाल में पेट्रोल 113.20 नेपाली रुपए है, जिसका भारतीय मुद्रा में मूल्य 70.75 रुपये, वहीं डीजल 96.20 नेपाली रुपए बिक रहा है जिसका भारतीय मुद्रा में कीमत 60.12 रुपए होता है',\n",
       " 'मामले में पुलिस ने मृतका के छोटे भाई और मां को ही गिरफ्तार किया है।',\n",
       " 'उनके साथ बातें करें।',\n",
       " 'फिर भी भर्ती प्रक्रिया पूरी नहीं की जा रही।',\n",
       " 'उनके बारे में लोगों को कोई भी जानकारी नहीं है।',\n",
       " 'इस बात की जानकारी उन्होंने खुद सोशल मीडिया के जरिए दी थी।',\n",
       " 'मामले में दोनों पक्ष ने एक दूसरे पर मुकदमा दर्ज कराया था।',\n",
       " 'ये लोग भी अभी तक रिहा नहीं हुए हैं.',\n",
       " 'शहीद भगतसिंह का जन्म दिवस मनाया',\n",
       " 'उस समय पुलिस का कोई भी जवान मौजूद नहीं था।',\n",
       " 'मुंबई-पुणे हाईवे पर उनकी गाड़ी का एक्सीडेंट हो गया।',\n",
       " 'दोनों की कोई साझी सीमा तो है नहीं.',\n",
       " 'सरसों के तेल का दीपक लगाएं।',\n",
       " 'यह कमेटी दस दिन में अपनी रिपोर्ट पंजाब एंड हरियाणा हाईकोर्ट को देगी।',\n",
       " 'जानकारी के मुताबिक दुर्घटनाग्रस्त कार में तीन लोग सवार थे।',\n",
       " 'थोड़ी देर के बाद पुलिस मौके पर पहुंची तथा उसने दरवाजा खोला।',\n",
       " 'साथ ही आपके स्वास्थ्य के लिए हानिकारक बन सकते हैँ।',\n",
       " 'इस मूवी के शीर्षक पर अभी तक बात नहीं बन पाई है।',\n",
       " 'यह अध्ययन ‘जर्नल ऑफ न्यूट्रिशियन’ नामक पत्रिका में प्रकाशित हुआ है।',\n",
       " 'सुनकर विश्वास नहीं होता लेकिन यही सच्चाई है.',\n",
       " 'मैच में जीत के बाद श्रीलंका के कप्तान से हाथ मिलाते भारतीय बल्लेबाज विराट कोहली।',\n",
       " 'जिन दो लोगों की रिपोर्ट पॉजीटिव आई है।',\n",
       " 'वहीं सचिन तेंदुलर अपनी पति अंजली और बेटे के साथ नजर आएं। जहां सचिन ने ऑरेंज कलर के कुर्ते के साथ क्रीम चूडीदार पायजामा पहना। वहीं अंजली ग्रीन-ब्लू कलर की सिल्क साड़ी में नजर आईं। वह काफी खूबसूरत नजर आ रही थी।',\n",
       " 'हादसे में इसके साथी को भी गंभीर चोंटे आई थी।',\n",
       " 'मकर : नवीन संबंधों में आकषर्ण बढ़ेगी।',\n",
       " 'इस फ\\u200dिल्\\u200dम को आम दर्शकों और क्र\\u200dिटिक्\\u200dस के अच्\\u200dछे रिव्\\u200dयूज मिले।',\n",
       " 'घटनास्थल पर लोगों की भारी भीड़ जुट गई।',\n",
       " 'वह अपनी शर्टलेस तस्वीरे सोशल मीडिया में शेयर करते रहते है।',\n",
       " 'पुलिस ने पोक्सो एक्ट में मामला दर्ज करके जांच शुरु की।',\n",
       " 'पिता को हम अस्पताल ले गए.',\n",
       " 'आरोपीयों ने ना तो उनको नौकरी दिलवाई ओर ना ही उनके पैसे लोटाए।',\n",
       " 'गनीमत रही कोई बड़ा हादसा नही हुआ।',\n",
       " 'Hrithik Roshan Fight Scenes On Chikni Chameli Song काम के मोर्चे पर ऋतिक को आखिरी बार टाइगर श्रॉफ और वाणी कपूर के साथ फिल्म वॉर में देखा गया था।',\n",
       " 'जबकि 266 मौतें बढ़ गई।',\n",
       " 'इसमें सेल्फी के लिए ड्यूल फ्रंट कैमरा उपलब्ध होगा।',\n",
       " 'इसी तरह पेन कार्ड को आधार से लिंक करने की अंतिम तिथि को भी आगे बढ़ाकर 30 जून कर दिया है।',\n",
       " 'राजस्थान बोर्ड द्वारा पूरक परीक्षाओं का आयोजन 3 सितंबर से 12 सितंबर तक किया गया था।',\n",
       " 'प्रदेश भर में भाजपा सरकार ने जो जन-जन के लिए कल्याणकारी नीतियां बनाई हैं, जिससे प्रत्येक वर्ग को फायदा मिला है।',\n",
       " 'उन्होंने बताया कि पुलिस ने मामला दर्ज कर लिया है तथा मामले की जांच की जा रही है.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "364e428d-68cb-4024-a78d-cf2b423c550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_LANG = \"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e83bfc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ============================================================\n",
    "# # Eval data (Urdu ALIF corpus)\n",
    "# # ============================================================\n",
    "# DATASET_NAME = \"orature/ALIF_Urdu_Corpus_AUC\"\n",
    "# TARGET_LANG  = \"ur\"\n",
    "# START = 0 # different across partition of job\n",
    "# MAX_EVAL = 30 # set it to 5000\n",
    "\n",
    "# def load_eval_texts(limit: int, start: int = 0) -> List[str]:\n",
    "#     ds = load_dataset(DATASET_NAME, split=\"train\")\n",
    "#     end = min(start + limit, len(ds))\n",
    "#     ds = ds.select(range(start, end))\n",
    "#     return [t for t in ds[\"Data\"] if isinstance(t, str) and t.strip()]\n",
    "\n",
    "# eval_texts = load_eval_texts(MAX_EVAL, START)\n",
    "# print(f\"[Data] Loaded {len(eval_texts)} Urdu eval texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a031369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Adapters on HF\n",
    "# ============================================================\n",
    "ADAPTERS = {\n",
    "    \"ur\": \"kanwal-mehreen18/urdu_lora_adapter\",\n",
    "    \"tr\": \"anniew666/tr_lora_adapter\",\n",
    "    \"pa\": \"anniew666/pa_lora_adapter\",\n",
    "    \"ms\": \"anniew666/ms_lora_adapter\",\n",
    "    \"fa\": \"anniew666/fa_lora_adapter\",\n",
    "    \"bn\": \"anniew666/bn_lora_adapter\",\n",
    "    \"ar\": \"anniew666/ar_lora_adapter\",\n",
    "}\n",
    "ALL_LANGS = list(ADAPTERS.keys())\n",
    "\n",
    "# Fixed baseline weights (partners chosen adaptively, weights fixed)\n",
    "FIXED_WEIGHTS  = (0.70, 0.15, 0.15)   # target, partner1, partner2\n",
    "\n",
    "# ============================================================\n",
    "# Stored statistics: BPE + centroids\n",
    "# ============================================================\n",
    "\n",
    "# Absolute project root on the cluster\n",
    "ART_DIR = Path.cwd() / \"MLLM_adaptation/statistics\"\n",
    "BPE_TOPK = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae6d23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bpe_json(lang: str) -> Dict:\n",
    "    p = ART_DIR / f\"{lang}.bpe.top{BPE_TOPK}.json\"\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        obj = json.load(f)\n",
    "    token_ids = np.array(obj[\"token_ids\"], dtype=np.int64)\n",
    "    probs     = np.array(obj[\"probs\"], dtype=np.float64)\n",
    "    probs     = probs / probs.sum() if probs.sum() > 0 else np.ones_like(probs)/len(probs)\n",
    "    return {\"token_ids\": token_ids, \"probs\": probs}\n",
    "\n",
    "def load_embed_json(lang: str) -> Dict:\n",
    "    p = ART_DIR / f\"{lang}.embed.json\"\n",
    "    with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "        obj = json.load(f)\n",
    "    c = np.array(obj[\"centroid\"], dtype=np.float32)\n",
    "    c = c / (np.linalg.norm(c) + 1e-12)\n",
    "    return {\"centroid\": c, \"dim\": int(obj[\"dim\"])}\n",
    "\n",
    "bpe_refs = {lg: load_bpe_json(lg) for lg in ALL_LANGS}\n",
    "emb_refs = {lg: load_embed_json(lg) for lg in ALL_LANGS}\n",
    "# EMBED_DIM = emb_refs[TARGET_LANG][\"dim\"]\n",
    "# print(f\"[Stats] Loaded BPE + centroids. EMBED_DIM={EMBED_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a96dfde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Embedding + BPE similarity helpers\n",
    "# ============================================================\n",
    "MAX_TOKENIZE_LEN = 512\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_one(text: str) -> np.ndarray:\n",
    "    enc = base_tokenizer(\n",
    "        [text],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_TOKENIZE_LEN,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "    out = emb_model(**enc, output_hidden_states=True)\n",
    "    last = out.hidden_states[-1]\n",
    "    mask = enc[\"attention_mask\"].unsqueeze(-1).type_as(last)\n",
    "    pooled = (last * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1e-6)\n",
    "    pooled = torch.nn.functional.normalize(pooled, p=2, dim=1)\n",
    "    pooled = pooled.to(torch.float32)\n",
    "    return pooled[0].detach().cpu().numpy()\n",
    "\n",
    "def empirical_bpe_histogram(text: str, support_tokens: np.ndarray) -> np.ndarray:\n",
    "    ids = base_tokenizer(text, add_special_tokens=False)[\"input_ids\"]\n",
    "    ids = [i for i in ids if i not in SPECIAL_IDS]\n",
    "    if not ids:\n",
    "        return np.ones(len(support_tokens), dtype=np.float64) / len(support_tokens)\n",
    "    counts = np.zeros(len(support_tokens), dtype=np.float64)\n",
    "    idx = {int(t): j for j, t in enumerate(support_tokens.tolist())}\n",
    "    for tid in ids:\n",
    "        j = idx.get(int(tid))\n",
    "        if j is not None:\n",
    "            counts[j] += 1.0\n",
    "    if counts.sum() == 0:\n",
    "        counts += 1e-8\n",
    "    return counts / counts.sum()\n",
    "\n",
    "def bpe_sim_jsd(p_input: np.ndarray, p_ref: np.ndarray) -> float:\n",
    "    d = jensenshannon(p_input, p_ref, base=2.0)\n",
    "    return 1.0 - float(d)\n",
    "\n",
    "def cos_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a)*np.linalg.norm(b) + 1e-12))\n",
    "\n",
    "def softmax_weights(scores: List[float], temp: float = 0.07) -> List[float]:\n",
    "    x = np.array(scores, dtype=np.float64) / max(1e-8, temp)\n",
    "    x = x - x.max()\n",
    "    w = np.exp(x)\n",
    "    return (w / w.sum()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8c43918",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_SCHEMES = {\n",
    "    \"bpe_only\":   (1.0,  0.0),\n",
    "    \"emb_only\":   (0.0,  1.0),\n",
    "    \"mix_25_75\":  (0.25, 0.75),\n",
    "    \"mix_50_50\":  (0.50, 0.50),\n",
    "    \"mix_75_25\":  (0.75, 0.25),\n",
    "}\n",
    "\n",
    "TOP_N_PARTNERS   = 3\n",
    "INCLUDE_TARGET   = False\n",
    "MIN_ACCEPT_SIM   = 0.01\n",
    "SOFTMAX_TEMP     = 0.07\n",
    "AGREEMENT_GUARD  = 0.10\n",
    "\n",
    "def compute_per_lang_sims(text: str, evec: np.ndarray) -> List[Dict]:\n",
    "    per_lang = []\n",
    "    for lg in ALL_LANGS:\n",
    "        ref_b = bpe_refs[lg]\n",
    "        ref_e = emb_refs[lg]\n",
    "        p_in  = empirical_bpe_histogram(text, ref_b[\"token_ids\"])\n",
    "        b_sim = bpe_sim_jsd(p_in, ref_b[\"probs\"])\n",
    "        e_sim = cos_sim(evec, ref_e[\"centroid\"])\n",
    "        per_lang.append({\"lang\": lg, \"bpe_sim\": b_sim, \"emb_sim\": e_sim})\n",
    "    return per_lang\n",
    "\n",
    "def select_adapters(per_lang: List[Dict], scheme: str, target_lang: str):\n",
    "    alpha, beta = SIM_SCHEMES[scheme]\n",
    "\n",
    "    scored = []\n",
    "    for r in per_lang:\n",
    "        b, e = r[\"bpe_sim\"], r[\"emb_sim\"]\n",
    "        if alpha > 0 and beta > 0 and abs(b - e) > AGREEMENT_GUARD:\n",
    "            s = (alpha*b + beta*e) * 0.9\n",
    "        else:\n",
    "            s = alpha*b + beta*e\n",
    "        scored.append({**r, \"scheme_score\": float(max(0.0, min(1.0, s)))})\n",
    "\n",
    "    ranked = sorted(scored, key=lambda x: x[\"scheme_score\"], reverse=True)\n",
    "    top_score = ranked[0][\"scheme_score\"]\n",
    "\n",
    "    chosen = []\n",
    "    if INCLUDE_TARGET and any(x[\"lang\"] == target_lang for x in ranked):\n",
    "        chosen.append(next(x for x in ranked if x[\"lang\"] == target_lang))\n",
    "\n",
    "    need = (1 + TOP_N_PARTNERS) if (INCLUDE_TARGET and chosen) else TOP_N_PARTNERS\n",
    "    for r in ranked:\n",
    "        if INCLUDE_TARGET and r[\"lang\"] == target_lang:\n",
    "            continue\n",
    "        if len(chosen) >= need:\n",
    "            break\n",
    "        chosen.append(r)\n",
    "\n",
    "    safety = False\n",
    "    if top_score < MIN_ACCEPT_SIM:\n",
    "        safety = True\n",
    "        chosen = [next(x for x in ranked if x[\"lang\"] == target_lang)] if (INCLUDE_TARGET and chosen) else [ranked[0]]\n",
    "\n",
    "    weights = softmax_weights([c[\"scheme_score\"] for c in chosen], temp=SOFTMAX_TEMP)\n",
    "    s = sum(weights)\n",
    "    weights = [w/s for w in weights]\n",
    "    return chosen, weights, top_score, safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6229b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Adapter caching + merge (KeyError-safe)  -- IN-MEMORY ONLY\n",
    "# ============================================================\n",
    "ADAPTER_CACHE = {}\n",
    "\n",
    "def _download_adapter(repo: str):\n",
    "    if repo in ADAPTER_CACHE:\n",
    "        return ADAPTER_CACHE[repo]\n",
    "\n",
    "    local = snapshot_download(repo)\n",
    "    cfg_path = Path(local) / \"adapter_config.json\"\n",
    "    with open(cfg_path, \"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "\n",
    "    p_bin = Path(local) / \"adapter_model.bin\"\n",
    "    if p_bin.exists():\n",
    "        sd = torch.load(str(p_bin), map_location=\"cpu\")\n",
    "    else:\n",
    "        p_st = Path(local) / \"adapter_model.safetensors\"\n",
    "        if p_st.exists():\n",
    "            sd = safe_load_file(str(p_st), device=\"cpu\")\n",
    "        else:\n",
    "            merged = {}\n",
    "            for sf in sorted(glob.glob(str(Path(local) / \"*.safetensors\"))):\n",
    "                merged.update(safe_load_file(sf, device=\"cpu\"))\n",
    "            sd = merged\n",
    "\n",
    "    ADAPTER_CACHE[repo] = {\"cfg\": cfg, \"sd\": sd}\n",
    "    return ADAPTER_CACHE[repo]\n",
    "\n",
    "def _is_lora_key(k: str) -> bool:\n",
    "    kk = k.lower()\n",
    "    return (\"lora_\" in kk) or (\"loraa\" in kk) or (\"lorab\" in kk)\n",
    "\n",
    "def soft_merge_three_sd(primary_repo: str, p1_repo: str, p2_repo: str,\n",
    "                        w0: float, w1: float, w2: float) -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Same merge as before, but returns a merged state_dict\n",
    "    and DOES NOT save anything to disk.\n",
    "    \"\"\"\n",
    "    prim = _download_adapter(primary_repo)\n",
    "    p1   = _download_adapter(p1_repo)\n",
    "    p2   = _download_adapter(p2_repo)\n",
    "\n",
    "    sds = [prim[\"sd\"], p1[\"sd\"], p2[\"sd\"]]\n",
    "    merged = {}\n",
    "\n",
    "    # merge LoRA keys\n",
    "    all_keys = set().union(*[sd.keys() for sd in sds])\n",
    "    for k in all_keys:\n",
    "        if not _is_lora_key(k):\n",
    "            continue\n",
    "        tens = []\n",
    "        base = None\n",
    "        for sd in sds:\n",
    "            if k in sd and isinstance(sd[k], torch.Tensor):\n",
    "                tens.append(sd[k])\n",
    "                base = sd[k] if base is None else base\n",
    "            else:\n",
    "                tens.append(torch.zeros_like(base) if base is not None else None)\n",
    "        if any(t is None for t in tens):\n",
    "            continue\n",
    "        merged[k] = w0*tens[0] + w1*tens[1] + w2*tens[2]\n",
    "\n",
    "    # copy non-LoRA keys from primary (modules_to_save, etc.)\n",
    "    for k, v in prim[\"sd\"].items():\n",
    "        if not _is_lora_key(k):\n",
    "            merged[k] = v\n",
    "\n",
    "    return merged\n",
    "\n",
    "def load_adapter_from_repo(adapter_repo: str):\n",
    "    \"\"\"\n",
    "    Load the base model + a LoRA adapter from Hugging Face / local repo,\n",
    "    without using Unsloth. Uses the same BASE_MODEL_NAME and DTYPE.\n",
    "    \"\"\"\n",
    "    # Load base model\n",
    "    m = AutoModelForCausalLM.from_pretrained(\n",
    "        BASE_MODEL_NAME,\n",
    "        torch_dtype=DTYPE,\n",
    "    )\n",
    "\n",
    "    # Attach LoRA adapter\n",
    "    m = PeftModel.from_pretrained(m, adapter_repo)\n",
    "\n",
    "    # Optional: disable cache for safety with some PEFT configs\n",
    "    try:\n",
    "        m.config.use_cache = False\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Make sure the active adapter is set\n",
    "    try:\n",
    "        m.set_adapter(m.active_adapter)\n",
    "    except Exception:\n",
    "        if hasattr(m, \"peft_config\") and len(m.peft_config):\n",
    "            m.set_adapter(list(m.peft_config.keys())[0])\n",
    "\n",
    "    return m.to(DEVICE).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae75b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def score_one(model, text: str, max_len: int = 256):\n",
    "    enc = base_tokenizer([text], padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "    out = model(input_ids=enc[\"input_ids\"], attention_mask=enc[\"attention_mask\"], labels=enc[\"input_ids\"])\n",
    "    loss = float(out.loss.item())\n",
    "    ppl  = float(math.exp(min(20.0, loss)))\n",
    "    toks = int(enc[\"attention_mask\"].sum().item())\n",
    "    return {\"loss\": loss, \"ppl\": ppl, \"avg_logprob\": -loss, \"entropy\": loss, \"tokens\": toks}\n",
    "\n",
    "@torch.no_grad()\n",
    "def score_one_base(text: str, max_len: int = 256):\n",
    "    \"\"\"\n",
    "    Baseline: LLaMA only (no adapters).\n",
    "    Uses emb_model directly as the base LM.\n",
    "    \"\"\"\n",
    "    enc = base_tokenizer([text], padding=True, truncation=True,\n",
    "                         max_length=max_len, return_tensors=\"pt\")\n",
    "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "    out = emb_model(input_ids=enc[\"input_ids\"],\n",
    "                    attention_mask=enc[\"attention_mask\"],\n",
    "                    labels=enc[\"input_ids\"])\n",
    "    loss = float(out.loss.item())\n",
    "    ppl  = float(math.exp(min(20.0, loss)))\n",
    "    toks = int(enc[\"attention_mask\"].sum().item())\n",
    "    return {\"loss\": loss, \"ppl\": ppl, \"avg_logprob\": -loss, \"entropy\": loss, \"tokens\": toks}\n",
    "\n",
    "def score_merge(text: str, primary: str, partners: List[str], weights: List[float]):\n",
    "    \"\"\"\n",
    "    Merge in-memory, inject into a primary PeftModel, score, discard.\n",
    "    No tmp_dir / disk writes.\n",
    "    \"\"\"\n",
    "    if len(partners) == 0:\n",
    "        raise ValueError(\"score_merge expects partners; single handled separately.\")\n",
    "\n",
    "    p1 = partners[0]\n",
    "    p2 = partners[1] if len(partners) > 1 else partners[0]\n",
    "    p3 = partners[2] if len(partners) > 2 else partners[0]\n",
    "\n",
    "    w0, w1, w2 = weights[:3]\n",
    "    s = w0 + w1 + w2\n",
    "    w0, w1, w2 = (w0/s, w1/s, w2/s) if s > 0 else (1.0, 0.0, 0.0)\n",
    "\n",
    "    merged_sd = soft_merge_three_sd(\n",
    "        ADAPTERS[p1], ADAPTERS[p2], ADAPTERS[p3],\n",
    "        w0, w1, w2\n",
    "    )\n",
    "\n",
    "    # Load base + primary adapter, then overwrite weights in-memory\n",
    "    mdl = load_adapter_from_repo(ADAPTERS[p1])\n",
    "    active = getattr(mdl, \"active_adapter\", None) or list(mdl.peft_config.keys())[0]\n",
    "    set_peft_model_state_dict(mdl, merged_sd, adapter_name=active, ignore_mismatched_sizes=True)\n",
    "\n",
    "    metrics = score_one(mdl, text)\n",
    "    del mdl; torch.cuda.empty_cache()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c6dd6e6-feef-43ee-9b3b-947e81f44759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def score_one(model, text: str, max_len: int = 256):\n",
    "#     enc = base_tokenizer([text], padding=True, truncation=True, max_length=max_len, return_tensors=\"pt\")\n",
    "#     enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "#     out = model(input_ids=enc[\"input_ids\"], attention_mask=enc[\"attention_mask\"], labels=enc[\"input_ids\"])\n",
    "#     loss = float(out.loss.item())\n",
    "#     ppl  = float(math.exp(min(20.0, loss)))\n",
    "#     toks = int(enc[\"attention_mask\"].sum().item())\n",
    "#     return {\"loss\": loss, \"ppl\": ppl, \"avg_logprob\": -loss, \"entropy\": loss, \"tokens\": toks}\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def score_one_base(text: str, max_len: int = 256):\n",
    "#     \"\"\"\n",
    "#     Baseline: LLaMA only (no adapters).\n",
    "#     Uses emb_model directly as the base LM.\n",
    "#     \"\"\"\n",
    "#     enc = base_tokenizer([text], padding=True, truncation=True,\n",
    "#                          max_length=max_len, return_tensors=\"pt\")\n",
    "#     enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
    "#     out = emb_model(input_ids=enc[\"input_ids\"],\n",
    "#                     attention_mask=enc[\"attention_mask\"],\n",
    "#                     labels=enc[\"input_ids\"])\n",
    "#     loss = float(out.loss.item())\n",
    "#     ppl  = float(math.exp(min(20.0, loss)))\n",
    "#     toks = int(enc[\"attention_mask\"].sum().item())\n",
    "#     return {\"loss\": loss, \"ppl\": ppl, \"avg_logprob\": -loss, \"entropy\": loss, \"tokens\": toks}\n",
    "\n",
    "# def score_merge(text: str, primary: str, partners: List[str], weights: List[float]):\n",
    "#     \"\"\"\n",
    "#     Merge in-memory, inject into a primary PeftModel, score, discard.\n",
    "#     No tmp_dir / disk writes.\n",
    "#     \"\"\"\n",
    "#     if len(partners) == 0:\n",
    "#         raise ValueError(\"score_merge expects partners; single handled separately.\")\n",
    "\n",
    "#     p1 = partners[0]\n",
    "#     p2 = partners[1] if len(partners) > 1 else partners[0]\n",
    "\n",
    "#     w0, w1, w2 = weights[:3]\n",
    "#     s = w0 + w1 + w2\n",
    "#     w0, w1, w2 = (w0/s, w1/s, w2/s) if s > 0 else (1.0, 0.0, 0.0)\n",
    "\n",
    "#     merged_sd = soft_merge_three_sd(\n",
    "#         ADAPTERS[primary], ADAPTERS[p1], ADAPTERS[p2],\n",
    "#         w0, w1, w2\n",
    "#     )\n",
    "\n",
    "#     # Load base + primary adapter, then overwrite weights in-memory\n",
    "#     mdl = load_adapter_from_repo(ADAPTERS[primary])\n",
    "#     active = getattr(mdl, \"active_adapter\", None) or list(mdl.peft_config.keys())[0]\n",
    "#     set_peft_model_state_dict(mdl, merged_sd, adapter_name=active, ignore_mismatched_sizes=True)\n",
    "\n",
    "#     metrics = score_one(mdl, text)\n",
    "#     del mdl; torch.cuda.empty_cache()\n",
    "#     return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "defe7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single_model = load_adapter_from_repo(ADAPTERS[TARGET_LANG])\n",
    "# print(\"[Single] Loaded Urdu adapter once for all samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca95f52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d019765ab00a459b9353e8383198eb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30492f28dea84d73b2bda83d4cf446f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42809365fbb643f6a93df8715ab53547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/6101777/wangzn/adapter_mllm/.venv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:1222: UserWarning: Model has `tie_word_embeddings=True` and a tied layer is part of the adapter, but `ensure_weight_tying` is not set to True. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. Check the discussion here: https://github.com/huggingface/peft/issues/2777\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbd181e9c0d498798f74fbf8f01ebd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e588f331f07647fdb99d6c9e93c5a4a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61f78a59c5c48aab2f79ca5a80539b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fd5f0cd2394ac48a15366d7eba083e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c9a08d0f744de38041b733bea5cc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a200e308515649c597fb82e44c5d6d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d7987fa9e9409781834cb97f39d0cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1908e41652d3471ea9086ec7c81941cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7b7ed932b64bd28e6b513264433fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f68876d058495688e8fccaab2e6e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edcaa085ae8d4e6a80c51e930dcfa564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3ca8da13db406e8e0279096a0c6426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bbd9c3158641cbae78bb4daa49ed44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f13273fb54a4e798e3f817c53ae0362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acaefb28af340e38733714c57ad87a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ea9538c9c2490d925cf46524a6eefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e320217a834182ab20f7f5f68c3a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0667843dc2449b59eeaf40015133a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569cbf33e02a47e1a0870a67ed4d00fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be26daccde440cbab7b0e472a4115ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4a595f338546ddafe9dc65b0af8142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6312ca80bb8c4971804014861ed14050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9277c616042544da99aab2cad2e0be40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ca604b81a9493ba237d7c0c5f6382e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6129c449d0e740ea9a92d260930eb1f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c6b628a30246a4a62962c55ce5f37d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a723b7c1335541279207b10e584b302d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56e1af8e11a43d1b9a4acc718fe0709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0639b17b15c3403c805b2fd6d0bd6028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ed456221804ea0a2c16d4fb8b17aa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158a3d0aa538428bb59f48d558a6df47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d054723ab746f69f97380f221435e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f4bc1231dd4076846a4c24b6575590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5693c7926546477c9b022a82c8a29fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd00ed49585947f990b41523212c504d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcb459f596640ff8821e9bb3a158518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6609b69e675547bd95788d78028fcd95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2c7c0d17df4ba3ae515e0f855896f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc21d8fda37477ab7811b791c4bacf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f23f390eb10415f8915e8fcca20d5da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6710a66c279a445491132f59b738ac63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3813cbcb81674ef1b34a9f93830ff97e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6caf9a4485cd4e6696cb76996f739372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91904cd893344dd0ac136748be19ee03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d48d328a254dee81d761621b19007c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4128ccec9241cda3c4bae240807651",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088152ed537e4b20a5f426bc6f1af3d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889f1199a8b84d24833a16483645f5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c441a6b7cca54cfa81a23b4b675d8e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966589560c0a412b8527a7cac2f30bfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07417bec6d6241e3926283005222aa4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0c9d568e4a4d55a0c2f397484a0f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Per-input adaptive evaluation\n",
    "# ============================================================\n",
    "RESULTS = []\n",
    "t_start = time.time()\n",
    "w_t, w_p1, w_p2 = FIXED_WEIGHTS  # 0.70, 0.15, 0.15\n",
    "\n",
    "for i, txt in enumerate(eval_texts):\n",
    "    preview = txt[:160].replace(\"\\n\", \" \")\n",
    "    evec = embed_one(txt)\n",
    "    per_lang = compute_per_lang_sims(txt, evec)\n",
    "\n",
    "    # --- BASELINE: LLaMA only (no adapters) ---\n",
    "    base_metrics = score_one_base(txt)\n",
    "    RESULTS.append({\n",
    "        \"idx\": i, \"text_preview\": preview,\n",
    "        \"target_lang\": TARGET_LANG,\n",
    "        \"system\": \"base\",\n",
    "        \"sim_mode\": \"none\",\n",
    "        \"alpha_bpe\": None, \"beta_emb\": None,\n",
    "        \"choice_1_lang\": None, \"choice_1_weight\": None,\n",
    "        \"choice_2_lang\": None, \"choice_2_weight\": None,\n",
    "        \"choice_3_lang\": None, \"choice_3_weight\": None,\n",
    "        \"top_score\": None, \"safety_fallback\": False,\n",
    "        **base_metrics,\n",
    "    })\n",
    "\n",
    "    # # --- SINGLE baseline (reused Urdu adapter) ---\n",
    "    # single_metrics = score_one(single_model, txt)\n",
    "    # RESULTS.append({\n",
    "    #     \"idx\": i, \"text_preview\": preview,\n",
    "    #     \"target_lang\": TARGET_LANG,\n",
    "    #     \"system\": \"single\",\n",
    "    #     \"sim_mode\": \"none\",\n",
    "    #     \"alpha_bpe\": None, \"beta_emb\": None,\n",
    "    #     \"choice_1_lang\": TARGET_LANG, \"choice_1_weight\": 1.0,\n",
    "    #     \"choice_2_lang\": None, \"choice_2_weight\": None,\n",
    "    #     \"choice_3_lang\": None, \"choice_3_weight\": None,\n",
    "    #     \"top_score\": None, \"safety_fallback\": False,\n",
    "    #     **single_metrics,\n",
    "    # })\n",
    "\n",
    "    # --- FIXED baseline (partners chosen via mix_50_50, weights fixed) ---\n",
    "    chosen_fixed, _, top_score_fixed, safety_fixed = select_adapters(\n",
    "        per_lang, scheme=\"mix_50_50\", target_lang=TARGET_LANG\n",
    "    )\n",
    "    langs_fixed = [c[\"lang\"] for c in chosen_fixed if c[\"lang\"] != TARGET_LANG]\n",
    "\n",
    "    if len(langs_fixed) == 0:\n",
    "        # Fallback: just use single adapter metrics again\n",
    "        fixed_metrics = single_metrics\n",
    "        fp1 = fp2 = None\n",
    "    else:\n",
    "        if len(langs_fixed) == 1:\n",
    "            fp1 = fp2 = langs_fixed[0]\n",
    "        else:\n",
    "            fp1, fp2 = langs_fixed[:2]\n",
    "\n",
    "        fixed_metrics = score_merge(\n",
    "            txt, TARGET_LANG, [fp1, fp2], [w_t, w_p1, w_p2],\n",
    "        )\n",
    "\n",
    "    RESULTS.append({\n",
    "        \"idx\": i, \"text_preview\": preview,\n",
    "        \"target_lang\": TARGET_LANG,\n",
    "        \"system\": f\"fixed_mix50:{TARGET_LANG}+{fp1}+{fp2}\",\n",
    "        \"sim_mode\": \"fixed_mix_50_50\",\n",
    "        \"alpha_bpe\": 0.50, \"beta_emb\": 0.50,\n",
    "        \"choice_1_lang\": TARGET_LANG, \"choice_1_weight\": w_t,\n",
    "        \"choice_2_lang\": fp1, \"choice_2_weight\": w_p1,\n",
    "        \"choice_3_lang\": fp2, \"choice_3_weight\": w_p2,\n",
    "        \"top_score\": float(top_score_fixed) if langs_fixed else None,\n",
    "        \"safety_fallback\": bool(safety_fixed) if langs_fixed else False,\n",
    "        **fixed_metrics,\n",
    "    })\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7701b1-070b-46a2-8618-2b24a59eb4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, txt in enumerate(eval_texts):\n",
    "    preview = txt[:160].replace(\"\\n\", \" \")\n",
    "    evec = embed_one(txt)\n",
    "    per_lang = compute_per_lang_sims(txt, evec)\n",
    "    # --- ADAPTIVE per scheme ---\n",
    "    for scheme, (alpha, beta) in SIM_SCHEMES.items():\n",
    "        chosen, weights, top_score, safety = select_adapters(per_lang, scheme, TARGET_LANG)\n",
    "        print(chosen)\n",
    "        print(weights)\n",
    "        langs = [c[\"lang\"] for c in chosen]\n",
    "        partners = [lg for lg in langs if lg != TARGET_LANG]\n",
    "\n",
    "        if len(partners) == 0:\n",
    "            metrics = score_one(single_model, txt)\n",
    "        else:\n",
    "            metrics = score_merge(\n",
    "                txt, TARGET_LANG, partners, weights\n",
    "            )\n",
    "\n",
    "        RESULTS.append({\n",
    "            \"idx\": i, \"text_preview\": preview,\n",
    "            \"target_lang\": TARGET_LANG,\n",
    "            \"system\": f\"adaptive:{scheme}\",\n",
    "            \"sim_mode\": scheme,\n",
    "            \"alpha_bpe\": alpha, \"beta_emb\": beta,\n",
    "            \"choice_1_lang\": langs[0] if len(langs)>0 else None,\n",
    "            \"choice_1_weight\": weights[0] if len(weights)>0 else None,\n",
    "            \"choice_2_lang\": langs[1] if len(langs)>1 else None,\n",
    "            \"choice_2_weight\": weights[1] if len(weights)>1 else None,\n",
    "            \"choice_3_lang\": langs[2] if len(langs)>2 else None,\n",
    "            \"choice_3_weight\": weights[2] if len(weights)>2 else None,\n",
    "            \"top_score\": float(top_score),\n",
    "            \"safety_fallback\": bool(safety),\n",
    "            **metrics,\n",
    "        })\n",
    "\n",
    "    if (i+1) % 10 == 0:\n",
    "        elapsed = (time.time() - t_start)/60\n",
    "        print(f\"[{i+1}/{len(eval_texts)}] done | elapsed ~{elapsed:.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb13719-28e8-422e-9b61-6c8faf23a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(RESULTS)\n",
    "df.to_csv(\"hindi_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90be18d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msocket\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m df = \u001b[43mpd\u001b[49m.DataFrame(RESULTS)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Save results inside the project\u001b[39;00m\n\u001b[32m     12\u001b[39m RESULTS_DIR = PROJECT_ROOT / \u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Save + summary (per-run file, safe for parallel jobs)\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import socket\n",
    "import os\n",
    "\n",
    "df = pd.DataFrame(RESULTS)\n",
    "\n",
    "# Save results inside the project\n",
    "RESULTS_DIR = PROJECT_ROOT / \"results\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Unique run ID: hostname + PID + timestamp\n",
    "run_id = f\"{socket.gethostname()}_{os.getpid()}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "out_csv = RESULTS_DIR / f\"ur_eval_{run_id}.csv\"\n",
    "\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"\\n✅ Saved per-input results:\", out_csv)\n",
    "\n",
    "summary = (\n",
    "    df.groupby(\"system\")[\"ppl\"]\n",
    "      .mean()\n",
    "      .reset_index()\n",
    "      .sort_values(\"ppl\")\n",
    ")\n",
    "\n",
    "print(\"\\n=== Avg PPL per system ===\")\n",
    "display(summary)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac65bb88-77dd-429b-b170-00a7d8da68d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(RESULTS)\n",
    "df.to_csv(\"hindi.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7b3443-91a9-4fdf-86e8-c80d4f857456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
